{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayushraj16/-Signature-Forgery-Detection-using-Siamese-Network-CEDAR-Dataset-/blob/main/forgery_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wfHeQIOhSg77"
      },
      "outputs": [],
      "source": [
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJJ0qoFpTvYZ"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"shreelakshmigp/cedardataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "INOV-bugWEMd"
      },
      "outputs": [],
      "source": [
        "# prompt: using the above dataset path , create a signature forgery detection system , siamese network with cedar dataset , also add an interface to insert the signature images .for interface use gradio\n",
        "\n",
        "!pip install torch torchvision torchmetrics pytorch-lightning\n",
        "!pip install transformers datasets\n",
        "\n",
        "import os\n",
        "import gradio as gr\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import pytorch_lightning as pl\n",
        "from torchvision.models import resnet18\n",
        "from torchmetrics.functional import accuracy\n",
        "\n",
        "# Define the dataset class\n",
        "class SignatureDataset(Dataset):\n",
        "    def __init__(self, base_path, transform=None):\n",
        "        self.base_path = base_path\n",
        "        self.transform = transform\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "        self.authentic_signatures = {} # To group authentic signatures by writer\n",
        "\n",
        "        # Assume the dataset structure is like:\n",
        "        # base_path/\n",
        "        #   original/\n",
        "        #     writer_id/\n",
        "        #       signature_image.png\n",
        "        #   forged/\n",
        "        #     writer_id/\n",
        "        #       signature_image.png\n",
        "\n",
        "        original_path = os.path.join(base_path, 'original')\n",
        "        forged_path = os.path.join(base_path, 'forged')\n",
        "\n",
        "        print(f\"Checking for original signatures in: {original_path}\")\n",
        "        print(f\"Checking for forged signatures in: {forged_path}\")\n",
        "\n",
        "        # Collect authentic signatures\n",
        "        if os.path.exists(original_path):\n",
        "            for writer_id in os.listdir(original_path):\n",
        "                writer_dir = os.path.join(original_path, writer_id)\n",
        "                if os.path.isdir(writer_dir):\n",
        "                    authentic_imgs = [\n",
        "                        os.path.join(writer_dir, img) for img in os.listdir(writer_dir) if img.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
        "                    ]\n",
        "                    if authentic_imgs:\n",
        "                        self.authentic_signatures[writer_id] = authentic_imgs\n",
        "                    # else:\n",
        "                        # print(f\"No image files found in authentic directory for writer {writer_id}: {writer_dir}\")\n",
        "                # else:\n",
        "                    # print(f\"Not a directory: {writer_dir}\")\n",
        "        # else:\n",
        "            # print(f\"Original signatures path not found: {original_path}\")\n",
        "\n",
        "\n",
        "        # Collect pairs for training (authentic-authentic and authentic-forged)\n",
        "        # This is a simplified approach. A more robust approach would involve creating balanced pairs.\n",
        "        print(f\"Found {len(self.authentic_signatures)} writers with authentic signatures.\")\n",
        "        if not self.authentic_signatures:\n",
        "             print(\"No authentic signatures found. Cannot create pairs.\")\n",
        "             print(f\"Expected original signatures in {original_path}\")\n",
        "             # You might want to raise an error or handle this case explicitly if no authentic signatures are found\n",
        "             # raise ValueError(\"No authentic signatures found in the dataset.\")\n",
        "\n",
        "\n",
        "        for writer_id, auth_sigs in self.authentic_signatures.items():\n",
        "            # Add authentic-authentic pairs (simplified: just the first authentic with others)\n",
        "            if len(auth_sigs) > 1:\n",
        "                for i in range(1, len(auth_sigs)):\n",
        "                    self.image_paths.append((auth_sigs[0], auth_sigs[i]))\n",
        "                    self.labels.append(1.0) # 1 for authentic\n",
        "\n",
        "            # Add authentic-forged pairs\n",
        "            writer_forged_path = os.path.join(forged_path, writer_id)\n",
        "            if os.path.exists(writer_forged_path):\n",
        "                forged_files = [img for img in os.listdir(writer_forged_path) if img.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "                if forged_files:\n",
        "                    if auth_sigs: # Ensure there's at least one authentic signature to pair with\n",
        "                         for forged_img_name in forged_files:\n",
        "                            self.image_paths.append((auth_sigs[0], os.path.join(writer_forged_path, forged_img_name)))\n",
        "                            self.labels.append(0.0) # 0 for forged\n",
        "                    # else:\n",
        "                        # print(f\"No authentic signatures found for writer {writer_id} to pair with forged.\")\n",
        "                # else:\n",
        "                     # print(f\"No forged image files found for writer {writer_id} in: {writer_forged_path}\")\n",
        "            # else:\n",
        "                # print(f\"Forged signatures path not found for writer {writer_id}: {writer_forged_path}\")\n",
        "\n",
        "\n",
        "        print(f\"Found {len(self.image_paths)} image pairs.\")\n",
        "\n",
        "        if len(self.image_paths) == 0:\n",
        "            print(\"Error: No image pairs were created. Please check the dataset path and structure.\")\n",
        "            print(f\"Base path used: {base_path}\")\n",
        "            print(f\"Original path checked: {original_path}, Exists: {os.path.exists(original_path)}\")\n",
        "            print(f\"Forged path checked: {forged_path}, Exists: {os.path.exists(forged_path)}\")\n",
        "            if os.path.exists(original_path):\n",
        "                 print(f\"Listing contents of original path: {os.listdir(original_path)[:5]}...\") # print first 5 items\n",
        "            if os.path.exists(forged_path):\n",
        "                 print(f\"Listing contents of forged path: {os.listdir(forged_path)[:5]}...\") # print first 5 items\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img1_path, img2_path = self.image_paths[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        img1 = Image.open(img1_path).convert('RGB')\n",
        "        img2 = Image.open(img2_path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            img1 = self.transform(img1)\n",
        "            img2 = self.transform(img2)\n",
        "\n",
        "        return img1, img2, torch.tensor(label, dtype=torch.float32)\n",
        "\n",
        "# Define the Siamese Network\n",
        "class SiameseNetwork(pl.LightningModule):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.encoder = resnet18(weights='ResNet18_Weights.DEFAULT')\n",
        "        # Remove the classification head\n",
        "        self.encoder = torch.nn.Sequential(*(list(self.encoder.children())[:-1]))\n",
        "\n",
        "        # Add a linear layer to reduce feature dimensions (optional, depends on task)\n",
        "        # Example: if resnet18 outputs 512, reduce to 128\n",
        "        # self.fc = nn.Linear(512, 128)\n",
        "\n",
        "        # For signature verification, we typically use contrastive loss or triplet loss.\n",
        "        # We don't need a final classification layer here, as we calculate distance.\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        # Encode each image\n",
        "        encoded_x1 = self.encoder(x1).squeeze() # Remove spatial dimensions\n",
        "        encoded_x2 = self.encoder(x2).squeeze() # Remove spatial dimensions\n",
        "\n",
        "        # Optional: Apply the linear layer\n",
        "        # encoded_x1 = self.fc(encoded_x1)\n",
        "        # encoded_x2 = self.fc(encoded_x2)\n",
        "\n",
        "        # Return the encoded features\n",
        "        return encoded_x1, encoded_x2\n",
        "\n",
        "    def get_distance(self, x1, x2):\n",
        "         # Encode and calculate L2 distance\n",
        "        encoded_x1, encoded_x2 = self(x1, x2)\n",
        "        distance = torch.pairwise_distance(encoded_x1, encoded_x2, p=2)\n",
        "        return distance\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        img1, img2, labels = batch\n",
        "        # Use contrastive loss\n",
        "        # Distance between encoded images\n",
        "        distance = self.get_distance(img1, img2)\n",
        "\n",
        "        # Define contrastive loss function manually or use available implementations\n",
        "        # Contrastive Loss: L = y * D^2 + (1-y) * max(0, margin - D)^2\n",
        "        # y=1 for similar pairs, y=0 for dissimilar pairs\n",
        "        margin = 1.0 # Hyperparameter\n",
        "        loss = labels * torch.pow(distance, 2) + (1 - labels) * torch.pow(torch.clamp(margin - distance, min=0.0), 2)\n",
        "        loss = torch.mean(loss)\n",
        "\n",
        "        self.log('train_loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = optim.Adam(self.parameters(), lr=1e-4)\n",
        "        return optimizer\n",
        "\n",
        "# Data transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)), # Resize images\n",
        "    transforms.ToTensor(),        # Convert to PyTorch tensor\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # ImageNet normalization\n",
        "])\n",
        "\n",
        "# --- Training (Optional - you might load a pre-trained model) ---\n",
        "# Prepare dataset and dataloader\n",
        "# Assuming the path variable from the previous cell is the base path\n",
        "if 'path' in locals() and path is not None:\n",
        "    # Check if the expected subdirectories exist in the path\n",
        "    expected_original_path = os.path.join(path, 'original')\n",
        "    expected_forged_path = os.path.join(path, 'forged')\n",
        "\n",
        "    if os.path.exists(expected_original_path) and os.path.exists(expected_forged_path):\n",
        "        dataset = SignatureDataset(path, transform=transform)\n",
        "\n",
        "        # Check if the dataset is empty before creating the DataLoader\n",
        "        if len(dataset) > 0:\n",
        "            # Split into train and validation (optional)\n",
        "            # train_size = int(0.8 * len(dataset))\n",
        "            # val_size = len(dataset) - train_size\n",
        "            # train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "\n",
        "            train_dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "            # val_dataloader = DataLoader(val_dataset, batch_size=32)\n",
        "\n",
        "            # Initialize and train the model\n",
        "            model = SiameseNetwork()\n",
        "            trainer = pl.Trainer(max_epochs=10) # Train for 10 epochs\n",
        "            # trainer.fit(model, train_dataloader, val_dataloader) # If you have validation\n",
        "            trainer.fit(model, train_dataloader)\n",
        "\n",
        "            print(\"Training complete.\")\n",
        "\n",
        "            # Save the trained model\n",
        "            torch.save(model.state_dict(), 'siamese_signature_model.pth')\n",
        "            print(\"Model saved to siamese_signature_model.pth\")\n",
        "        else:\n",
        "            print(\"Dataset is empty. No image pairs found to train the model.\")\n",
        "            print(\"Please check the dataset structure and ensure image files are present in the expected directories.\")\n",
        "\n",
        "    else:\n",
        "        print(f\"Expected subdirectories 'original' and 'forged' not found in {path}.\")\n",
        "        print(\"Skipping training.\")\n",
        "\n",
        "else:\n",
        "    print(\"Dataset path not found. Skipping training.\")\n",
        "    # If skipping training, you would load a pre-trained model here.\n",
        "    # model = SiameseNetwork()\n",
        "    # model.load_state_dict(torch.load('path/to/your/pretrained_model.pth'))\n",
        "    # model.eval() # Set model to evaluation mode\n",
        "\n",
        "# --- Gradio Interface ---\n",
        "\n",
        "# Load the trained model for inference\n",
        "# Ensure the model is loaded whether trained now or pre-trained\n",
        "model = SiameseNetwork()\n",
        "if os.path.exists('siamese_signature_model.pth'):\n",
        "    model.load_state_dict(torch.load('siamese_signature_model.pth'))\n",
        "    print(\"Loaded trained model for inference.\")\n",
        "else:\n",
        "     # If no trained model is found, you might want to raise an error or load a default pre-trained one\n",
        "     print(\"No trained model found. Please ensure training was successful or a model file exists.\")\n",
        "     # Example of loading a dummy state dict if needed to initialize the model structure\n",
        "     # (This won't perform meaningful inference without proper weights)\n",
        "     # dummy_state_dict = model.state_dict()\n",
        "     # torch.save(dummy_state_dict, 'siamese_signature_model.pth')\n",
        "     # model.load_state_dict(torch.load('siamese_signature_model.pth'))\n",
        "\n",
        "\n",
        "model.eval() # Set model to evaluation mode\n",
        "\n",
        "# Function for prediction\n",
        "def predict_forgery(authentic_signature_image, test_signature_image):\n",
        "    if authentic_signature_image is None or test_signature_image is None:\n",
        "        return \"Please upload both authentic and test signatures.\"\n",
        "\n",
        "    # Apply the same transformations as during training\n",
        "    img1_tensor = transform(Image.fromarray(authentic_signature_image).convert('RGB')).unsqueeze(0) # Add batch dimension\n",
        "    img2_tensor = transform(Image.fromarray(test_signature_image).convert('RGB')).unsqueeze(0)\n",
        "\n",
        "    # Move tensors to the same device as the model\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    img1_tensor = img1_tensor.to(device)\n",
        "    img2_tensor = img2_tensor.to(device)\n",
        "\n",
        "    with torch.no_grad(): # Disable gradient calculation\n",
        "        distance = model.get_distance(img1_tensor, img2_tensor)\n",
        "\n",
        "    # You need to determine a threshold for the distance.\n",
        "    # Distances below the threshold indicate similar signatures (authentic),\n",
        "    # and distances above indicate dissimilar (forged).\n",
        "    # This threshold should be determined during validation/testing on a separate dataset.\n",
        "    # For demonstration, let's use a placeholder threshold.\n",
        "    threshold = 0.5 # This is a placeholder. You MUST find a suitable threshold.\n",
        "\n",
        "    if distance.item() < threshold:\n",
        "        result = f\"Signatures are similar (likely Authentic). Distance: {distance.item():.4f}\"\n",
        "    else:\n",
        "        result = f\"Signatures are dissimilar (likely Forged). Distance: {distance.item():.4f}\"\n",
        "\n",
        "    return result\n",
        "\n",
        "# Create the Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=predict_forgery,\n",
        "    inputs=[\n",
        "        gr.Image(type=\"numpy\", label=\"Upload Authentic Signature\"),\n",
        "        gr.Image(type=\"numpy\", label=\"Upload Test Signature\")\n",
        "    ],\n",
        "    outputs=\"text\",\n",
        "    title=\"Signature Forgery Detection\",\n",
        "    description=\"Upload an authentic signature and a test signature to check for forgery.\"\n",
        ")\n",
        "\n",
        "# Launch the interface\n",
        "print(\"Launching Gradio interface...\")\n",
        "iface.launch(debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIqkJeLeSaon"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyOlq2m8so48uDOLQ68JdGf+",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}